{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pytorch 기반 회귀 모델 구현] <hr>\n",
    "- Layer => Full-Connected Layer, Linear\n",
    "- 손실함수 => MSELoss, MAELoss, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "from torchmetrics.functional import mean_squared_error, r2_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../DATA/BostonHousing.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HousingDF = pd.read_csv(data_file)\n",
    "HousingDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   crim     506 non-null    float64\n",
      " 1   zn       506 non-null    float64\n",
      " 2   indus    506 non-null    float64\n",
      " 3   chas     506 non-null    int64  \n",
      " 4   nox      506 non-null    float64\n",
      " 5   rm       506 non-null    float64\n",
      " 6   age      506 non-null    float64\n",
      " 7   dis      506 non-null    float64\n",
      " 8   rad      506 non-null    int64  \n",
      " 9   tax      506 non-null    int64  \n",
      " 10  ptratio  506 non-null    float64\n",
      " 11  b        506 non-null    float64\n",
      " 12  lstat    506 non-null    float64\n",
      " 13  medv     506 non-null    float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "HousingDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HousingDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tax\n",
       "666    132\n",
       "307     40\n",
       "403     30\n",
       "437     15\n",
       "304     14\n",
       "      ... \n",
       "285      1\n",
       "198      1\n",
       "256      1\n",
       "244      1\n",
       "313      1\n",
       "Name: count, Length: 66, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HousingDF['tax'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureDF = HousingDF[HousingDF.columns[:-1]]\n",
    "featureDF = featureDF[featureDF.columns.difference(['chas', 'rad'])]\n",
    "targetSR = HousingDF[HousingDF.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [-1, -2, 5]])\n",
    "a.max(1, keepdim = True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 사용자 데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 정의\n",
    "class BostonDS(Dataset):\n",
    "\n",
    "    # 필요한 데이터 전처리 수행도 가능 => 정규화 등\n",
    "    def __init__(self, x_data, y_data):\n",
    "        super().__init__()\n",
    "        # x, y 데이터 => ndarray\n",
    "        x_data = x_data.values if isinstance(x_data, pd.DataFrame) else x_data\n",
    "        y_data = y_data.values if isinstance(y_data, pd.Series) else y_data\n",
    "        \n",
    "        self.feature = torch.FloatTensor(x_data)\n",
    "        self.target = torch.FloatTensor(y_data)\n",
    "        self.length = self.feature.shape[0]\n",
    "        #self.norm_feature = self.normalization()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.feature[index], self.target[index]\n",
    "    \n",
    "    # 데이터 정규화 기능 함수\n",
    "    # def normalization(self):\n",
    "    #     for col in range(self.feature.shape[1]):\n",
    "    #         MAX = self.feature.max(dim = 0)[0][col]\n",
    "    #         MIN = self.feature.min(dim = 0)[0][col]\n",
    "    #         if (MAX - MIN) != 0:\n",
    "    #             self.feature[:, col] = (self.feature[:, col] - MIN) / (MAX - MIN)\n",
    "    #         else:\n",
    "    #             epsilon = 10^(-6)\n",
    "    #             self.feature[:, col] = (self.feature[:, col] - MIN) / (MAX - MIN + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(featureDF, targetSR,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                      test_size = 0.1,\n",
    "                                                      random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_SCALER = StandardScaler()\n",
    "MY_SCALER.fit(X_train)\n",
    "scaled_X_train = MY_SCALER.transform(X_train)\n",
    "scaled_X_val = MY_SCALER.transform(X_val)\n",
    "scaled_X_test = MY_SCALER.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDS = BostonDS(scaled_X_train, y_train)\n",
    "validDS = BostonDS(scaled_X_val, y_val)\n",
    "testDS = BostonDS(scaled_X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 생성\n",
    "# drop_last 매개변수 : 배치 사이즈로 데이터셋 분리 후 남는 데이터 처리 방법 설정 [기본 : False]\n",
    "BATCH_SIZE = 10\n",
    "trainDL = DataLoader(trainDS, batch_size = BATCH_SIZE, drop_last = True)\n",
    "validDL = DataLoader(validDS, batch_size = BATCH_SIZE, drop_last = True)\n",
    "testDL = DataLoader(testDS, batch_size = BATCH_SIZE, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size = 10\n",
      "trainDS => 363개, validDS => 41개, testDS => 102개\n",
      "trainDL => 36개, validDL => 4개, testDL => 10개\n"
     ]
    }
   ],
   "source": [
    "# Epoch당 반복 단위\n",
    "print(f'batch_size = {BATCH_SIZE}')\n",
    "print(f'trainDS => {len(trainDS)}개, validDS => {len(validDS)}개, testDS => {len(testDS)}개')\n",
    "print(f'trainDL => {len(trainDL)}개, validDL => {len(validDL)}개, testDL => {len(testDL)}개')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, 4),\n",
    "            nn.BatchNorm1d(num_features = 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4, 2),\n",
    "            nn.BatchNorm1d(num_features = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(2, 1))\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                torch.nn.init.kaiming_normal_(layer.weight.data)\n",
    "                torch.nn.init.zeros_(layer.bias.data) \n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 2.2.2  Device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=11, out_features=4, bias=True)\n",
      "    (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4, out_features=2, bias=True)\n",
      "    (5): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=2, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### ===> Optimizer, Objective Function 설정\n",
    "MY_MODEL = LinearModel(11).to(DEVICE)\n",
    "\n",
    "OPTIMIZER = torch.optim.Adam(MY_MODEL.parameters())\n",
    "LOSS_FN = nn.MSELoss()\n",
    "SCHEDULER = ReduceLROnPlateau(OPTIMIZER, mode = 'min', patience = 5)\n",
    "print(MY_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=11, out_features=4, bias=True)\n",
      "Linear(in_features=4, out_features=2, bias=True)\n",
      "Linear(in_features=2, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for layer in MY_MODEL.modules():\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 학습 진행함수 \n",
    "def training():\n",
    "    # 학습모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 활성화 \n",
    "    MY_MODEL.train()\n",
    "    \n",
    "    # 배치크기 만큼 학습 진행 및 저장\n",
    "    train_report=[[], []]\n",
    "    for idx, (feature, target)  in enumerate(trainDL):\n",
    "        # 배치크기만큼의 학습 데이터 준비\n",
    "        feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "        \n",
    "        # 학습\n",
    "        pre_traget = MY_MODEL(feature)\n",
    "        target = target.unsqueeze(1)\n",
    "        \n",
    "        # 손실계산\n",
    "        loss = LOSS_FN(pre_traget, target)\n",
    "        train_report[0].append(loss.item())\n",
    "        \n",
    "        # 성능 평가\n",
    "        acc = r2_score(pre_traget, target)\n",
    "        train_report[1].append(acc.item())\n",
    "        \n",
    "        # W,b업데이트\n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "    \n",
    "    # 에포크 단위로 학습 모델 저장\n",
    "    # torch.save(model, './model/my_model.pt')\n",
    "    \n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    train_loss = np.mean(train_report[0])\n",
    "    train_accuracy = np.mean(train_report[1])\n",
    "\n",
    "    #print(f'\\n[{epoch+1} Train ] Loss ==> {train_loss:.4f} Accuracy ==> {train_accuracy:.2f}\\n')\n",
    "    \n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 검증 및 테스트 진행함수 \n",
    "def testing():\n",
    "    # 학습모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 활성화 \n",
    "    MY_MODEL.eval()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        # 배치크기 만큼 학습 진행 및 저장\n",
    "        valid_report=[[], []]\n",
    "        for idx, (feature, target) in enumerate(validDL):\n",
    "            # 배치크기만큼의 학습 데이터 준비\n",
    "            feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "        \n",
    "            # 학습\n",
    "            pre_traget = MY_MODEL(feature)\n",
    "            target = target.unsqueeze(1)\n",
    "        \n",
    "            # 손실계산\n",
    "            loss = LOSS_FN(pre_traget, target)\n",
    "            valid_report[0].append(loss)\n",
    "            \n",
    "            # 성능 평가 \n",
    "            acc = r2_score(pre_traget, target)\n",
    "            valid_report[1].append(acc)\n",
    "\n",
    "    #testing_type = 'Valid' if kind == 'valid' else 'Test'\n",
    "        \n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    val_loss = np.mean(valid_report[0])\n",
    "    val_accuarcy = np.mean(valid_report[1])\n",
    "\n",
    "    #print(f'[{epoch+1} {testing_type} ] Loss ==> {valid_loss:.4f} Acc ==> {valid_accuarcy:.2f}\\n')\n",
    "    \n",
    "    return val_loss, val_accuarcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH: 1], \tMSE Loss: 611.4171, \tTrain Accuracy: -8.50\n",
      "\n",
      "\n",
      "[EPOCH: 1], \tMSE Loss: 561.0781, \tVal Accuracy: -9.88\n",
      "\n",
      "\n",
      "[EPOCH: 2], \tMSE Loss: 604.8598, \tTrain Accuracy: -8.42\n",
      "\n",
      "\n",
      "[EPOCH: 2], \tMSE Loss: 556.7396, \tVal Accuracy: -9.79\n",
      "\n",
      "\n",
      "[EPOCH: 3], \tMSE Loss: 600.1387, \tTrain Accuracy: -8.34\n",
      "\n",
      "\n",
      "[EPOCH: 3], \tMSE Loss: 554.3311, \tVal Accuracy: -9.74\n",
      "\n",
      "\n",
      "[EPOCH: 4], \tMSE Loss: 596.5798, \tTrain Accuracy: -8.24\n",
      "\n",
      "\n",
      "[EPOCH: 4], \tMSE Loss: 550.9536, \tVal Accuracy: -9.66\n",
      "\n",
      "\n",
      "[EPOCH: 5], \tMSE Loss: 589.8144, \tTrain Accuracy: -8.15\n",
      "\n",
      "\n",
      "[EPOCH: 5], \tMSE Loss: 547.7042, \tVal Accuracy: -9.59\n",
      "\n",
      "\n",
      "[EPOCH: 6], \tMSE Loss: 588.3133, \tTrain Accuracy: -8.09\n",
      "\n",
      "\n",
      "[EPOCH: 6], \tMSE Loss: 544.7639, \tVal Accuracy: -9.52\n",
      "\n",
      "\n",
      "[EPOCH: 7], \tMSE Loss: 582.2570, \tTrain Accuracy: -7.99\n",
      "\n",
      "\n",
      "[EPOCH: 7], \tMSE Loss: 542.4207, \tVal Accuracy: -9.47\n",
      "\n",
      "\n",
      "[EPOCH: 8], \tMSE Loss: 575.6915, \tTrain Accuracy: -7.99\n",
      "\n",
      "\n",
      "[EPOCH: 8], \tMSE Loss: 535.6500, \tVal Accuracy: -9.33\n",
      "\n",
      "\n",
      "[EPOCH: 9], \tMSE Loss: 569.6431, \tTrain Accuracy: -7.90\n",
      "\n",
      "\n",
      "[EPOCH: 9], \tMSE Loss: 529.9633, \tVal Accuracy: -9.22\n",
      "\n",
      "\n",
      "[EPOCH: 10], \tMSE Loss: 560.4875, \tTrain Accuracy: -7.69\n",
      "\n",
      "\n",
      "[EPOCH: 10], \tMSE Loss: 524.8733, \tVal Accuracy: -9.12\n",
      "\n",
      "\n",
      "[EPOCH: 11], \tMSE Loss: 563.3822, \tTrain Accuracy: -7.60\n",
      "\n",
      "\n",
      "[EPOCH: 11], \tMSE Loss: 517.5886, \tVal Accuracy: -8.98\n",
      "\n",
      "\n",
      "[EPOCH: 12], \tMSE Loss: 552.4220, \tTrain Accuracy: -7.54\n",
      "\n",
      "\n",
      "[EPOCH: 12], \tMSE Loss: 515.3932, \tVal Accuracy: -8.93\n",
      "\n",
      "\n",
      "[EPOCH: 13], \tMSE Loss: 549.9614, \tTrain Accuracy: -7.55\n",
      "\n",
      "\n",
      "[EPOCH: 13], \tMSE Loss: 505.3816, \tVal Accuracy: -8.74\n",
      "\n",
      "\n",
      "[EPOCH: 14], \tMSE Loss: 543.2220, \tTrain Accuracy: -7.41\n",
      "\n",
      "\n",
      "[EPOCH: 14], \tMSE Loss: 502.3759, \tVal Accuracy: -8.69\n",
      "\n",
      "\n",
      "[EPOCH: 15], \tMSE Loss: 531.8785, \tTrain Accuracy: -7.30\n",
      "\n",
      "\n",
      "[EPOCH: 15], \tMSE Loss: 501.3696, \tVal Accuracy: -8.67\n",
      "\n",
      "\n",
      "[EPOCH: 16], \tMSE Loss: 531.8401, \tTrain Accuracy: -7.13\n",
      "\n",
      "\n",
      "[EPOCH: 16], \tMSE Loss: 496.6509, \tVal Accuracy: -8.58\n",
      "\n",
      "\n",
      "[EPOCH: 17], \tMSE Loss: 519.1898, \tTrain Accuracy: -7.02\n",
      "\n",
      "\n",
      "[EPOCH: 17], \tMSE Loss: 482.3041, \tVal Accuracy: -8.30\n",
      "\n",
      "\n",
      "[EPOCH: 18], \tMSE Loss: 512.5512, \tTrain Accuracy: -6.79\n",
      "\n",
      "\n",
      "[EPOCH: 18], \tMSE Loss: 477.8932, \tVal Accuracy: -8.23\n",
      "\n",
      "\n",
      "[EPOCH: 19], \tMSE Loss: 503.7382, \tTrain Accuracy: -6.73\n",
      "\n",
      "\n",
      "[EPOCH: 19], \tMSE Loss: 471.7574, \tVal Accuracy: -8.11\n",
      "\n",
      "\n",
      "[EPOCH: 20], \tMSE Loss: 510.0960, \tTrain Accuracy: -6.87\n",
      "\n",
      "\n",
      "[EPOCH: 20], \tMSE Loss: 466.4427, \tVal Accuracy: -8.03\n",
      "\n",
      "\n",
      "[EPOCH: 21], \tMSE Loss: 499.8900, \tTrain Accuracy: -6.56\n",
      "\n",
      "\n",
      "[EPOCH: 21], \tMSE Loss: 457.1702, \tVal Accuracy: -7.83\n",
      "\n",
      "\n",
      "[EPOCH: 22], \tMSE Loss: 489.4596, \tTrain Accuracy: -6.50\n",
      "\n",
      "\n",
      "[EPOCH: 22], \tMSE Loss: 458.4470, \tVal Accuracy: -7.86\n",
      "\n",
      "\n",
      "[EPOCH: 23], \tMSE Loss: 489.5740, \tTrain Accuracy: -6.55\n",
      "\n",
      "\n",
      "[EPOCH: 23], \tMSE Loss: 448.3575, \tVal Accuracy: -7.67\n",
      "\n",
      "\n",
      "[EPOCH: 24], \tMSE Loss: 477.5682, \tTrain Accuracy: -6.27\n",
      "\n",
      "\n",
      "[EPOCH: 24], \tMSE Loss: 446.5483, \tVal Accuracy: -7.64\n",
      "\n",
      "\n",
      "[EPOCH: 25], \tMSE Loss: 456.4443, \tTrain Accuracy: -5.91\n",
      "\n",
      "\n",
      "[EPOCH: 25], \tMSE Loss: 427.4858, \tVal Accuracy: -7.28\n",
      "\n",
      "\n",
      "[EPOCH: 26], \tMSE Loss: 459.7615, \tTrain Accuracy: -6.07\n",
      "\n",
      "\n",
      "[EPOCH: 26], \tMSE Loss: 425.1804, \tVal Accuracy: -7.24\n",
      "\n",
      "\n",
      "[EPOCH: 27], \tMSE Loss: 448.9682, \tTrain Accuracy: -5.82\n",
      "\n",
      "\n",
      "[EPOCH: 27], \tMSE Loss: 417.4174, \tVal Accuracy: -7.10\n",
      "\n",
      "\n",
      "[EPOCH: 28], \tMSE Loss: 451.7044, \tTrain Accuracy: -5.97\n",
      "\n",
      "\n",
      "[EPOCH: 28], \tMSE Loss: 408.0032, \tVal Accuracy: -6.92\n",
      "\n",
      "\n",
      "[EPOCH: 29], \tMSE Loss: 445.4987, \tTrain Accuracy: -5.87\n",
      "\n",
      "\n",
      "[EPOCH: 29], \tMSE Loss: 397.7070, \tVal Accuracy: -6.72\n",
      "\n",
      "\n",
      "[EPOCH: 30], \tMSE Loss: 448.0982, \tTrain Accuracy: -5.91\n",
      "\n",
      "\n",
      "[EPOCH: 30], \tMSE Loss: 390.9288, \tVal Accuracy: -6.60\n",
      "\n",
      "\n",
      "[EPOCH: 31], \tMSE Loss: 434.0669, \tTrain Accuracy: -5.56\n",
      "\n",
      "\n",
      "[EPOCH: 31], \tMSE Loss: 385.6091, \tVal Accuracy: -6.49\n",
      "\n",
      "\n",
      "[EPOCH: 32], \tMSE Loss: 439.1003, \tTrain Accuracy: -5.67\n",
      "\n",
      "\n",
      "[EPOCH: 32], \tMSE Loss: 376.8224, \tVal Accuracy: -6.33\n",
      "\n",
      "\n",
      "[EPOCH: 33], \tMSE Loss: 413.0940, \tTrain Accuracy: -5.46\n",
      "\n",
      "\n",
      "[EPOCH: 33], \tMSE Loss: 375.9429, \tVal Accuracy: -6.32\n",
      "\n",
      "\n",
      "[EPOCH: 34], \tMSE Loss: 423.2393, \tTrain Accuracy: -5.43\n",
      "\n",
      "\n",
      "[EPOCH: 34], \tMSE Loss: 358.2275, \tVal Accuracy: -5.94\n",
      "\n",
      "\n",
      "[EPOCH: 35], \tMSE Loss: 402.3949, \tTrain Accuracy: -5.28\n",
      "\n",
      "\n",
      "[EPOCH: 35], \tMSE Loss: 364.1872, \tVal Accuracy: -6.08\n",
      "\n",
      "\n",
      "[EPOCH: 36], \tMSE Loss: 392.8369, \tTrain Accuracy: -5.12\n",
      "\n",
      "\n",
      "[EPOCH: 36], \tMSE Loss: 353.1261, \tVal Accuracy: -5.88\n",
      "\n",
      "\n",
      "[EPOCH: 37], \tMSE Loss: 406.6326, \tTrain Accuracy: -5.22\n",
      "\n",
      "\n",
      "[EPOCH: 37], \tMSE Loss: 342.4131, \tVal Accuracy: -5.67\n",
      "\n",
      "\n",
      "[EPOCH: 38], \tMSE Loss: 390.3866, \tTrain Accuracy: -5.19\n",
      "\n",
      "\n",
      "[EPOCH: 38], \tMSE Loss: 344.9381, \tVal Accuracy: -5.70\n",
      "\n",
      "\n",
      "[EPOCH: 39], \tMSE Loss: 397.8153, \tTrain Accuracy: -5.13\n",
      "\n",
      "\n",
      "[EPOCH: 39], \tMSE Loss: 339.7044, \tVal Accuracy: -5.63\n",
      "\n",
      "\n",
      "[EPOCH: 40], \tMSE Loss: 362.4577, \tTrain Accuracy: -4.54\n",
      "\n",
      "\n",
      "[EPOCH: 40], \tMSE Loss: 332.4600, \tVal Accuracy: -5.46\n",
      "\n",
      "\n",
      "[EPOCH: 41], \tMSE Loss: 374.0704, \tTrain Accuracy: -4.64\n",
      "\n",
      "\n",
      "[EPOCH: 41], \tMSE Loss: 310.7015, \tVal Accuracy: -5.03\n",
      "\n",
      "\n",
      "[EPOCH: 42], \tMSE Loss: 372.2763, \tTrain Accuracy: -4.72\n",
      "\n",
      "\n",
      "[EPOCH: 42], \tMSE Loss: 302.9220, \tVal Accuracy: -4.87\n",
      "\n",
      "\n",
      "[EPOCH: 43], \tMSE Loss: 391.7073, \tTrain Accuracy: -5.07\n",
      "\n",
      "\n",
      "[EPOCH: 43], \tMSE Loss: 306.5248, \tVal Accuracy: -4.96\n",
      "\n",
      "\n",
      "[EPOCH: 44], \tMSE Loss: 382.2484, \tTrain Accuracy: -4.77\n",
      "\n",
      "\n",
      "[EPOCH: 44], \tMSE Loss: 308.2836, \tVal Accuracy: -4.99\n",
      "\n",
      "\n",
      "[EPOCH: 45], \tMSE Loss: 372.4694, \tTrain Accuracy: -4.70\n",
      "\n",
      "\n",
      "[EPOCH: 45], \tMSE Loss: 296.5871, \tVal Accuracy: -4.77\n",
      "\n",
      "\n",
      "[EPOCH: 46], \tMSE Loss: 350.1728, \tTrain Accuracy: -4.43\n",
      "\n",
      "\n",
      "[EPOCH: 46], \tMSE Loss: 293.9781, \tVal Accuracy: -4.72\n",
      "\n",
      "\n",
      "[EPOCH: 47], \tMSE Loss: 350.5226, \tTrain Accuracy: -4.30\n",
      "\n",
      "\n",
      "[EPOCH: 47], \tMSE Loss: 292.3224, \tVal Accuracy: -4.68\n",
      "\n",
      "\n",
      "[EPOCH: 48], \tMSE Loss: 338.4891, \tTrain Accuracy: -4.18\n",
      "\n",
      "\n",
      "[EPOCH: 48], \tMSE Loss: 285.2369, \tVal Accuracy: -4.54\n",
      "\n",
      "\n",
      "[EPOCH: 49], \tMSE Loss: 353.6637, \tTrain Accuracy: -4.32\n",
      "\n",
      "\n",
      "[EPOCH: 49], \tMSE Loss: 295.3924, \tVal Accuracy: -4.76\n",
      "\n",
      "\n",
      "[EPOCH: 50], \tMSE Loss: 346.5581, \tTrain Accuracy: -4.29\n",
      "\n",
      "\n",
      "[EPOCH: 50], \tMSE Loss: 272.6849, \tVal Accuracy: -4.29\n",
      "\n",
      "\n",
      "[EPOCH: 51], \tMSE Loss: 338.0774, \tTrain Accuracy: -4.04\n",
      "\n",
      "\n",
      "[EPOCH: 51], \tMSE Loss: 271.1954, \tVal Accuracy: -4.29\n",
      "\n",
      "\n",
      "[EPOCH: 52], \tMSE Loss: 334.3588, \tTrain Accuracy: -4.39\n",
      "\n",
      "\n",
      "[EPOCH: 52], \tMSE Loss: 267.0767, \tVal Accuracy: -4.19\n",
      "\n",
      "\n",
      "[EPOCH: 53], \tMSE Loss: 310.5451, \tTrain Accuracy: -3.76\n",
      "\n",
      "\n",
      "[EPOCH: 53], \tMSE Loss: 256.1028, \tVal Accuracy: -3.98\n",
      "\n",
      "\n",
      "[EPOCH: 54], \tMSE Loss: 334.3855, \tTrain Accuracy: -3.93\n",
      "\n",
      "\n",
      "[EPOCH: 54], \tMSE Loss: 250.1252, \tVal Accuracy: -3.85\n",
      "\n",
      "\n",
      "[EPOCH: 55], \tMSE Loss: 325.4595, \tTrain Accuracy: -3.69\n",
      "\n",
      "\n",
      "[EPOCH: 55], \tMSE Loss: 239.3372, \tVal Accuracy: -3.61\n",
      "\n",
      "\n",
      "[EPOCH: 56], \tMSE Loss: 339.6875, \tTrain Accuracy: -4.22\n",
      "\n",
      "\n",
      "[EPOCH: 56], \tMSE Loss: 244.6357, \tVal Accuracy: -3.72\n",
      "\n",
      "\n",
      "[EPOCH: 57], \tMSE Loss: 315.4826, \tTrain Accuracy: -3.89\n",
      "\n",
      "\n",
      "[EPOCH: 57], \tMSE Loss: 244.1780, \tVal Accuracy: -3.71\n",
      "\n",
      "\n",
      "[EPOCH: 58], \tMSE Loss: 334.7302, \tTrain Accuracy: -3.87\n",
      "\n",
      "\n",
      "[EPOCH: 58], \tMSE Loss: 228.7874, \tVal Accuracy: -3.40\n",
      "\n",
      "\n",
      "[EPOCH: 59], \tMSE Loss: 345.6185, \tTrain Accuracy: -4.11\n",
      "\n",
      "\n",
      "[EPOCH: 59], \tMSE Loss: 227.9564, \tVal Accuracy: -3.39\n",
      "\n",
      "\n",
      "[EPOCH: 60], \tMSE Loss: 329.6720, \tTrain Accuracy: -3.80\n",
      "\n",
      "\n",
      "[EPOCH: 60], \tMSE Loss: 219.1295, \tVal Accuracy: -3.22\n",
      "\n",
      "\n",
      "[EPOCH: 61], \tMSE Loss: 312.6989, \tTrain Accuracy: -3.50\n",
      "\n",
      "\n",
      "[EPOCH: 61], \tMSE Loss: 223.7449, \tVal Accuracy: -3.29\n",
      "\n",
      "\n",
      "[EPOCH: 62], \tMSE Loss: 310.0141, \tTrain Accuracy: -3.87\n",
      "\n",
      "\n",
      "[EPOCH: 62], \tMSE Loss: 225.8288, \tVal Accuracy: -3.34\n",
      "\n",
      "\n",
      "[EPOCH: 63], \tMSE Loss: 296.8431, \tTrain Accuracy: -3.78\n",
      "\n",
      "\n",
      "[EPOCH: 63], \tMSE Loss: 226.3019, \tVal Accuracy: -3.36\n",
      "\n",
      "\n",
      "[EPOCH: 64], \tMSE Loss: 346.6264, \tTrain Accuracy: -4.20\n",
      "\n",
      "\n",
      "[EPOCH: 64], \tMSE Loss: 209.9399, \tVal Accuracy: -3.02\n",
      "\n",
      "\n",
      "[EPOCH: 65], \tMSE Loss: 320.5317, \tTrain Accuracy: -3.63\n",
      "\n",
      "\n",
      "[EPOCH: 65], \tMSE Loss: 209.3875, \tVal Accuracy: -3.01\n",
      "\n",
      "\n",
      "[EPOCH: 66], \tMSE Loss: 324.6691, \tTrain Accuracy: -3.97\n",
      "\n",
      "\n",
      "[EPOCH: 66], \tMSE Loss: 198.4667, \tVal Accuracy: -2.78\n",
      "\n",
      "\n",
      "[EPOCH: 67], \tMSE Loss: 295.3754, \tTrain Accuracy: -3.51\n",
      "\n",
      "\n",
      "[EPOCH: 67], \tMSE Loss: 213.1884, \tVal Accuracy: -3.10\n",
      "\n",
      "\n",
      "[EPOCH: 68], \tMSE Loss: 306.1683, \tTrain Accuracy: -3.81\n",
      "\n",
      "\n",
      "[EPOCH: 68], \tMSE Loss: 195.0584, \tVal Accuracy: -2.74\n",
      "\n",
      "\n",
      "[EPOCH: 69], \tMSE Loss: 299.3570, \tTrain Accuracy: -3.84\n",
      "\n",
      "\n",
      "[EPOCH: 69], \tMSE Loss: 202.2039, \tVal Accuracy: -2.86\n",
      "\n",
      "\n",
      "[EPOCH: 70], \tMSE Loss: 294.3788, \tTrain Accuracy: -3.58\n",
      "\n",
      "\n",
      "[EPOCH: 70], \tMSE Loss: 199.6086, \tVal Accuracy: -2.81\n",
      "\n",
      "\n",
      "[EPOCH: 71], \tMSE Loss: 303.1388, \tTrain Accuracy: -3.48\n",
      "\n",
      "\n",
      "[EPOCH: 71], \tMSE Loss: 199.8195, \tVal Accuracy: -2.82\n",
      "\n",
      "\n",
      "[EPOCH: 72], \tMSE Loss: 317.1706, \tTrain Accuracy: -3.90\n",
      "\n",
      "\n",
      "[EPOCH: 72], \tMSE Loss: 196.1760, \tVal Accuracy: -2.76\n",
      "\n",
      "\n",
      "[EPOCH: 73], \tMSE Loss: 281.9537, \tTrain Accuracy: -3.38\n",
      "\n",
      "\n",
      "[EPOCH: 73], \tMSE Loss: 184.3540, \tVal Accuracy: -2.49\n",
      "\n",
      "\n",
      "[EPOCH: 74], \tMSE Loss: 312.2503, \tTrain Accuracy: -3.86\n",
      "\n",
      "\n",
      "[EPOCH: 74], \tMSE Loss: 192.4446, \tVal Accuracy: -2.70\n",
      "\n",
      "\n",
      "[EPOCH: 75], \tMSE Loss: 296.4148, \tTrain Accuracy: -3.85\n",
      "\n",
      "\n",
      "[EPOCH: 75], \tMSE Loss: 183.1390, \tVal Accuracy: -2.49\n",
      "\n",
      "\n",
      "[EPOCH: 76], \tMSE Loss: 283.8785, \tTrain Accuracy: -3.45\n",
      "\n",
      "\n",
      "[EPOCH: 76], \tMSE Loss: 191.3245, \tVal Accuracy: -2.64\n",
      "\n",
      "\n",
      "[EPOCH: 77], \tMSE Loss: 329.4658, \tTrain Accuracy: -4.07\n",
      "\n",
      "\n",
      "[EPOCH: 77], \tMSE Loss: 188.1247, \tVal Accuracy: -2.60\n",
      "\n",
      "\n",
      "[EPOCH: 78], \tMSE Loss: 286.1730, \tTrain Accuracy: -3.36\n",
      "\n",
      "\n",
      "[EPOCH: 78], \tMSE Loss: 198.9802, \tVal Accuracy: -2.84\n",
      "\n",
      "\n",
      "[EPOCH: 79], \tMSE Loss: 268.9186, \tTrain Accuracy: -3.22\n",
      "\n",
      "\n",
      "[EPOCH: 79], \tMSE Loss: 184.6186, \tVal Accuracy: -2.52\n",
      "\n",
      "\n",
      "[EPOCH: 80], \tMSE Loss: 342.6322, \tTrain Accuracy: -4.33\n",
      "\n",
      "\n",
      "[EPOCH: 80], \tMSE Loss: 187.9825, \tVal Accuracy: -2.59\n",
      "\n",
      "Early stopping at epoch 80\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "loss_list = [[], []]\n",
    "accuracy_list = [[], []]\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    \n",
    "    train_loss, train_accuracy = training()\n",
    "    val_loss, val_accuracy = testing()\n",
    "    \n",
    "    print(f\"\\n[EPOCH: {epoch}], \\tMSE Loss: {train_loss:.4f}, \\tTrain Accuracy: {train_accuracy:.2f}\\n\")\n",
    "    print(f\"\\n[EPOCH: {epoch}], \\tMSE Loss: {val_loss:.4f}, \\tVal Accuracy: {val_accuracy:.2f}\\n\")\n",
    "\n",
    "    SCHEDULER.step(val_loss)\n",
    "    # 조기종료 기능 => 조건 : val_loss가 지정된 횟수이상 개선이 안되면 학습 종료\n",
    "    if SCHEDULER.num_bad_epochs >= SCHEDULER.patience:\n",
    "        print(f'Early stopping at epoch {epoch}')\n",
    "        break\n",
    "\n",
    "    loss_list[0].append(train_loss)\n",
    "    loss_list[1].append(val_loss)\n",
    "    accuracy_list[0].append(train_accuracy)\n",
    "    accuracy_list[1].append(val_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
